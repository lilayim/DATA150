## Using Data Science to Better Disaster Management and Response To Tsunamis in Japan

For Amartya Sen, human development meant the consistent expansion and enlargement of the people’s opportunities all while removing people’s unfreedoms. Working to understand the origins of disasters in Japan works towards bringing about transparency guarantees, a component of freedom that citizens are deprived of when subjected to danger due to mispredictions of these tsunamis and earthquakes. Asking myself the question: "How do we use data science to better disaster management and response to tsunamis in Japan?” was the basis to my research and enabled me to explore the dimensions of data science.

Before analyzing Japan’s previous evacuation disasters due to miscalculated information, it is vital to recognize that Japan leads in disaster preparation (Rauhala) due to its susceptibility to them. For one, Japan is an archipelago placed along the Ring of Fire, namely the Pacific earthquake belt, which is a place where many tectonic plates meet (MOJA). Also, the Asian monsoon climate region which Japan is a part of is one of the most vigorous climatic phenomena on Earth, resulting in constant rainfall and typhoons (Clift). Furthermore, Japan is in the circum-Pacific zone which almost all of the volcanoes of the world are located in (totals to be 83 active volcanoes). These are only a few of the reasons that make Japan extremely disaster prone, and urbanization is not helping. The rapid increasing concentration of population increases risks of the country experiencing natural disasters, especially as they get closer to the coasts and volcano locations. Japan, having survived the quake of 1923, devastations of World War II, and the earthquake in Kobe in 1995, has suffered more than enough to become experts in disaster preparedness. September 1st is declared Disaster Prevention Day; celebrations in schools include an evacuation drill and speeches from the Prime Minister (Rauhala). All in all, by analyzing these situations, we can understand how Japan was able to better their systems and earn this title.

Although Japan has experienced countless natural disasters due to its geographical location, The Great East Japan Earthquake and Tsunami in particular is known to be one of the most destructive tsunamis experienced. In March of 2011, a miscalculation regarding the Tohoku earthquake (which caused the tsunami) contributed to the loss of about twenty thousand people. The problem roots in the inability to find where and how much the sea surface at the epicenter rose after the earthquake started; finding how a tsunami began is key to create simulations and calculate movement. The JMA (Japan Meteorological Agency) uses P and S waves, which are two modes of seismic wave, to observe the delay between them and generate a multitude of possibilities for a calculated epicenter and magnitude. Basing their results on a magnitude 8 temblor, JMA concluded an underestimated magnitude of 7.9. The magnitude 9 earthquake took them by surprise, for the country experienced a tsunami of over 10m in height (3-6m difference from predicted). As a result, orders announced evacuation times longer than actually possible; the tsunami with thirty times the power they expected because of a single magnitude difference overcame existing seawalls and increased the death toll (Kamogawa).

Although extremely devastating, the Great East Japan Earthquake and Tsunami acted as a wake-up call to scientists and sparked an improvement to prediction analysis networks and evacuation methods. The National Research and Development Agency’s National Research Institute for Earth Science and Disaster Resilience came up with a data science method to lower the death toll for future tsunamis: the Japan Trench Earthquake and Tsunami Monitoring Network (also called the S-net). With construction starting in November 2011 and ending in March 2017, this large-scale seafloor network links 150 observatories along the Japan Trench (while also focusing on around the area of the Tohoku earthquake) in order to collect real-time data for disaster prevention. Monitoring through S-net data promotes long-term prediction of earthquakes which hence will provide reliable early earthquake and tsunami warnings. Within the S-net, seismometers, which are optical amplifier units used to measure the motion of the ground during earthquakes, are attached with two sets of voltage output accelerometers for redundancy. All of the observatories are connected to a single main cable. The S-net is favorable because everything covers an extremely wide region at a relatively low cost (Shin). It is also liked because it gathers data that is not only in real time, but also information that hasn’t been given in the past land-based observations. Usage of the s-net has just started, and it will only get and develop better from here (Mochizuki). 
	After the earthquake and tsunami, social media served as a lifeline for individuals affected. Social media carries massive amounts of structured and unstructured data in different formats (such as pictures, videos, sounds and locations) that aid in collecting and spreading information as datasets (Loon). The catastrophe stopped the land-line and mobile phones from working and text messages would not be dispatched quickly enough due to congestion. The social environment became uncertain for those experiencing the earthquake in the present, so people turned to media outlets and depend on instantaneous information. Media outlets were also crucial for communication with friends and family about safety. Nearly all mobile phones are Internet capable, so even though the land-line was clogged people with mobile phones still could contact others virtually. Mixi is a very popular service originating in Japan that helped at the time of the disaster. They added large image links to Google Person Finder and provided the home page with links to communities related to the disaster sectioned in categories like “general”, “affected person’s support information”, “regional”, and more. Twitter also helped by publishing explanations of how to use Twitter during the disaster and hashtags (Brett).

In observing the disaster recovery of 2011, simple vertical optical imagery is not enough to capture images of the damaged or collapsed buildings due to the Great East Japan Earthquake and Tsunami. About 107 thousand buildings were only collapsed (with many more damaged), so TSX intensity images were used to conduct the extraction of flooded areas and washed-away buildings. TerraSAR-X images detect the buildings that were damaged from the side-walls or lower parts and provide suitable mapping. TerraSAR-X and COSMO-SkyMed images are captured in high resolution with detailed surface information. The article displays pictures that focus specifically on the coastal zone of Tohoku, one of the more affected areas. Images displayed were captured with HH polarization, an azimuth resolution of 3.3, and a ground range resolution of 1.2 m. Other satellite images are displayed showing how preprocessing approaches were applied to find the radar reflectivity per unit area (in the ground range). This was found through a Sigma Naught value, and after finding backscattering coefficients from negative thirty to thirty dB. The mathematics behind solving for backscattering coefficients involve using matrices, tangents, and geometrical relationships to find different variables such as radar shadow areas and layover areas (Yoji).

Even ten years after the event, different data science methods are being introduced due to the 2011 earthquake and tsunami incident, including a tsunami forecasting approach using convolutional neural networks called CNNs. An article argues that CNNs are able to forecast requiring only 0.004 seconds as opposed to the 48 seconds forecasting experiments for Tohoku to generate 1,000 scenarios. CNN processes valuable data from dense tsunami and geodetic observation networks (which has a high possibility of this including data collected from the s-net on the Japan trench) and has many advantages including that (one) the cost is much lower than other simulations and (two) that there is no need for a source estimation process. The study presents multiple analyses of data including sensitivity analysis, noise waveforms, and calculus models of the 2011 Tohoku earthquake in order to prove that this method should be used and more widespread. (Makinoshima) 

In order to grasp a better understanding of disaster management in Japan, I placed my focus and research on one singular event: the Great East Japan Earthquake and Tsunami. I understood how the tragic events came about, how citizens responded and reacted to the event, and how scientists had utilized data science to prevent this in the future. However, with this way of proceeding, there are benefits and drawbacks that I experienced. By specifying one event I was able to scrutinize details and thoroughly understand the situation I was dealing with. However, the biggest gap in my literature review was that, because I only was working on one event, I was not able to analyze different data science methods that Japan made use of for other disasters in the country. My central research question that my investigation into a human development process will seek to answer will be: “How has The Great East Japan Earthquake and Tsunami been instrumental in helping scientists use and understand data science more?”. This question can be answered through my use of sources, because the majority of them explain data science methods used to figure out what caused the 2011 disaster, helped build observatories to prevent future massive earthquakes alike to this one, captured destroyed architecture from the catastrophe, aided humanity to utilize systems to communicate in urgent times, and provide possible future methods to analyze situations alike to this.

## Bibliography
Aoi, Shin, et al. “MOWLAS: Nied Observation Network for Earthquake, Tsunami and Volcano.” Earth, Planets and Space, Springer Berlin Heidelberg, 7 Sept. 2020, earth-planets-space.springeropen.com/articles/10.1186/s40623-020-01250-x.

​​Disaster prevention. MOFA. (n.d.). Retrieved October 24, 2021, from https://www.mofa.go.jp/policy/disaster/21st/2.html. 
Iwasaki, Yoji. Detection of Damage to Building Side-Walls Using High ... www.researchgate.net/publication/272883672_Detection_of_damage_to_building_side-walls_using_high-resolution_satellite_SAR_images.

Loon, R. V. (2021, June 6). The intersection of Data Science and Social Media. Simplilearn.com. Retrieved October 25, 2021, from https://www.simplilearn.com/intersection-of-data-science-and-social-media-article. 

Makinoshima, F., Oishi, Y., Yamazaki, T., Furumura, T., &amp; Imamura, F. (2021, April 15). Early forecasting of tsunami inundation from Tsunami and geodetic observation data with convolutional neural networks. Nature News. Retrieved October 25, 2021, from https://www.nature.com/articles/s41467-021-22348-0. 
Masahi, Kamogawa. “GPS, AIS, and More: Diversifying Tsunami Prediction Technology.” Nippon.com, 9 July 2020, www.nippon.com/en/japan-topics/g00876/.
Mochizuki, M. (n.d.). S-net project: Performance of a large-scale seafloor observation network for preventing and reducing seismic and tsunami disasters. IEEE Xplore. Retrieved October 25, 2021, from https://ieeexplore.ieee.org/document/8558823. 

P. D. Clift, A. H. (2021, September 29). Evolution of the asian monsoon. Eos. Retrieved October 24, 2021, from https://eos.org/science-updates/evolution-of-the-asian-monsoon. 

Peary, Brett. "Utilization of Social Media in the East Japan Earthquake and Tsunami and its Effectiveness." 12 July 2012. jsnds.org/jnds/34_1_1.pdf.
Rauhala, E. (2011, March 11). How Japan became a leader in disaster preparation. Time. Retrieved October 24, 2021, from http://content.time.com/time/world/article/0,8599,2058390,00.html. 




